# LATAM Data Engineering Challenge

En el presente repositorio se encontrarÃ¡n las soluciones los requerimientos planteados por el ejercicio. 
Los resultados esperados fueron los siguientes para cada uno de los ejercicios: 

- Fechas con mayor cantidad de trinos y usuario que mÃ¡s trinÃ³ respectivamente
    - [(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91'), (datetime.date(2021, 2, 21), 'Surrypuria'), (datetime.date(2021, 2, 22), 'preetysaini321'), (datetime.date(2021, 2, 24), 'preetysaini321')]

- Conteo de emojis: 
    -[('ğŸ™', 7286), ('ğŸ˜‚', 3072), ('ğŸšœ', 2972), ('âœŠ', 2411), ('ğŸŒ¾', 2182), ('ğŸ‡®', 2092), ('â¤', 1779), ('ğŸ¤£', 1668), ('ğŸ‘‡', 1108), ('ğŸ’š', 1040)]

- Top usuarios mencionados en el lote de trinos: 
    -[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019)]

## Estructura del repositorio

El arbol de archivos del repositorio es el siguiente: 
```
â”œâ”€â”€â”€pyspark_scripts
â”‚   â””â”€â”€â”€code
â”œâ”€â”€â”€src
â””â”€â”€â”€terraform
    â””â”€â”€â”€.terraform
        â”œâ”€â”€â”€modules
        â”‚   â”œâ”€â”€â”€bucket
        â”‚   â”‚   â”œâ”€â”€â”€.github
        â”‚   â”‚   â”‚   â””â”€â”€â”€workflows
        â”‚   â”‚   â”œâ”€â”€â”€build
        â”‚   â”‚   â”œâ”€â”€â”€docs
        â”‚   â”‚   â”œâ”€â”€â”€examples
        â”‚   â”‚   â”‚   â”œâ”€â”€â”€multiple_buckets
        â”‚   â”‚   â”‚   â””â”€â”€â”€simple_bucket
        â”‚   â”‚   â”œâ”€â”€â”€helpers
        â”‚   â”‚   â”œâ”€â”€â”€modules
        â”‚   â”‚   â”‚   â””â”€â”€â”€simple_bucket
        â”‚   â”‚   â””â”€â”€â”€test
        â”‚   â”‚       â”œâ”€â”€â”€integration
        â”‚   â”‚       â”‚   â””â”€â”€â”€multiple_buckets
        â”‚   â”‚       â””â”€â”€â”€setup
        â”‚   â””â”€â”€â”€gcs_buckets
        â”‚       â”œâ”€â”€â”€.github
        â”‚       â”‚   â””â”€â”€â”€workflows
        â”‚       â”œâ”€â”€â”€build
        â”‚       â”œâ”€â”€â”€docs
        â”‚       â”œâ”€â”€â”€examples
        â”‚       â”‚   â”œâ”€â”€â”€multiple_buckets
        â”‚       â”‚   â””â”€â”€â”€simple_bucket
        â”‚       â”œâ”€â”€â”€helpers
        â”‚       â”œâ”€â”€â”€modules
        â”‚       â”‚   â””â”€â”€â”€simple_bucket
        â”‚       â””â”€â”€â”€test
        â”‚           â”œâ”€â”€â”€integration
        â”‚           â”‚   â””â”€â”€â”€multiple_buckets
        â”‚           â””â”€â”€â”€setup
        â””â”€â”€â”€providers
            â””â”€â”€â”€registry.terraform.io
                â””â”€â”€â”€hashicorp
                    â”œâ”€â”€â”€archive
                    â”‚   â””â”€â”€â”€2.4.2
                    â”‚       â””â”€â”€â”€windows_amd64
                    â”œâ”€â”€â”€google
                    â”‚   â””â”€â”€â”€5.37.0
                    â”‚       â””â”€â”€â”€windows_amd64
                    â””â”€â”€â”€random
                        â””â”€â”€â”€3.6.2
                            â””â”€â”€â”€windows_amd64
```
El lenguaje de programaciÃ³n principal para el presente reto fue Python usando el Framework de procesamiento distribuido Spark mediante el API PySpark. Este lenguaje provee una robusta variedad de funciones y mÃ©todos para limpiar, procesar y escribir grandes volÃºmenes de datos de forma escalable. Adicionalmente, cuenta con una gran comunidad de desarrollo.
Se desarrollÃ³ en Terraform la infraestructura como cÃ³digo necesaria para crear un workflow de Dataproc y asÃ­ poder automatizar la ejecuciÃ³n de los jobs. 
Se requiere el cargue del archivo de trinos al bucket creado en el folder para tener el input disponible al cÃ³digo. Se realizÃ³ la prueba con el archivo pyspark_scripts\code\top_most_user_by_date.py. 
Adicionalmente, se deben ajustar los valores del proyecto de GCP donde se desee ejecutar el cÃ³digo. 

De igual forma, se creÃ³ un Dockerfile para tener disponible una aplicaciÃ³n contanerizada en caso de realizar pruebas en un local aisladamente. 

##EjecuciÃ³n del cÃ³digo terraform

En caso de querer ejecutar la infraestructura definida en Terraform se sugiere utilizar el archivo exec.bash que automatiza los llamados init,plan y apply: 
```
bash exec.bash  --Ambientes Linux
```